{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import statistics\n",
    "import random\n",
    "import heapq\n",
    "from scipy import optimize\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "# data = pd.read_csv('/Users/windyluan/Dropbox/VIS/Insight/Data/carSales2.csv')\n",
    "data = pd.read_csv('C:\\\\Users\\\\52497\\\\Dropbox\\\\VIS\\\\Insight\\\\Data\\\\carSales1.csv')\n",
    "# data = pd.read_csv('C:\\\\Users\\\\52497\\\\Dropbox\\\\VIS\\\\Insight\\\\Data\\\\carSales2.csv')\n",
    "# data = pd.read_csv('C:\\\\Users\\\\52497\\\\Dropbox\\\\VIS\\\\FactExtraction\\\\Data\\\\Emission.csv')\n",
    "# data = pd.read_csv('C:\\\\Users\\\\52497\\\\Dropbox\\\\VIS\\\\Insight\\\\Data\\\\aggregation.csv')\n",
    "# data = pd.read_csv('C:\\\\Users\\\\52497\\\\Dropbox\\\\VIS\\\\FactExtraction\\\\Data\\\\Census.csv')\n",
    "\n",
    "# data['Year'] = data['Year'].apply(lambda year_string: year_string.split('/')[0])\n",
    "# data['Year'] = data['Year'].apply(lambda time_str: time.mktime(datetime.datetime.strptime(time_str, \"%Y/%d/%m\").timetuple()))\n",
    "\n",
    "data = data.loc[(data!=0).any(axis=1)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "def subspace_ordering(feature_measures, df):\n",
    "    feature_unique_value_matrix = dict(zip(feature_measures,\n",
    "                                       [df[feature].nunique() for feature in feature_measures]))\n",
    "    sorted_feature_dict = {k: v for k, v in sorted(feature_unique_value_matrix.items(), key=lambda item: item[1], reverse=False)}\n",
    "    print(\"New Keys: \", list(sorted_feature_dict.keys()))\n",
    "    print(sorted_feature_dict)\n",
    "    return list(sorted_feature_dict.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         Year       Brand Category   Sales\n0    2007/1/1         BMW  Compact  142490\n1    2008/1/1         BMW  Compact  112464\n2    2009/1/1         BMW  Compact   90960\n3    2010/1/1         BMW  Compact  100910\n4    2011/1/1         BMW  Compact   94371\n..        ...         ...      ...     ...\n270  2007/1/1  Volkswagen      SUV    8812\n271  2008/1/1  Volkswagen      SUV    6755\n272  2009/1/1  Volkswagen      SUV    4392\n273  2010/1/1  Volkswagen      SUV    4713\n274  2011/1/1  Volkswagen      SUV    7535\n\n[275 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Brand</th>\n      <th>Category</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007/1/1</td>\n      <td>BMW</td>\n      <td>Compact</td>\n      <td>142490</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008/1/1</td>\n      <td>BMW</td>\n      <td>Compact</td>\n      <td>112464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2009/1/1</td>\n      <td>BMW</td>\n      <td>Compact</td>\n      <td>90960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010/1/1</td>\n      <td>BMW</td>\n      <td>Compact</td>\n      <td>100910</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011/1/1</td>\n      <td>BMW</td>\n      <td>Compact</td>\n      <td>94371</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>2007/1/1</td>\n      <td>Volkswagen</td>\n      <td>SUV</td>\n      <td>8812</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>2008/1/1</td>\n      <td>Volkswagen</td>\n      <td>SUV</td>\n      <td>6755</td>\n    </tr>\n    <tr>\n      <th>272</th>\n      <td>2009/1/1</td>\n      <td>Volkswagen</td>\n      <td>SUV</td>\n      <td>4392</td>\n    </tr>\n    <tr>\n      <th>273</th>\n      <td>2010/1/1</td>\n      <td>Volkswagen</td>\n      <td>SUV</td>\n      <td>4713</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>2011/1/1</td>\n      <td>Volkswagen</td>\n      <td>SUV</td>\n      <td>7535</td>\n    </tr>\n  </tbody>\n</table>\n<p>275 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_power_law(phi):\n",
    "    \"\"\"\n",
    "    :param: phi\n",
    "    :return: [breakdown_value, observation_value, predict_value]\n",
    "    \"\"\"\n",
    "    ordered_phi = {k: v for k, v in sorted(phi.items(), key=lambda item: item[1], reverse=True)}\n",
    "    keys = list(ordered_phi.keys())\n",
    "    values = list(ordered_phi.values())\n",
    "    max_value = max(values)\n",
    "    ydata = []\n",
    "    for i in values:\n",
    "        if i != max_value and i not in ydata:\n",
    "            ydata.append(i / max_value)\n",
    "    xdata = range(2, len(ydata) + 2)\n",
    "    logx = np.log10(xdata)\n",
    "    logy = np.log10(ydata)\n",
    "    pinit = [1.0, -1.0]\n",
    "\n",
    "    fitfunc = lambda p, x: p[0] + p[1] * x\n",
    "    errfunc = lambda p, x, y: (y - fitfunc(p, x))\n",
    "    powerLawFunc = lambda amp, index, x: amp * (x ** index)\n",
    "\n",
    "    try:\n",
    "        out = optimize.leastsq(errfunc, pinit, args=(logx, logy), full_output=1)\n",
    "\n",
    "        pfinal = out[0]\n",
    "        covar = out[1]\n",
    "\n",
    "        index = pfinal[1]\n",
    "        amp = 10.0 ** pfinal[0]\n",
    "        # indexErr = np.sqrt(covar[1][1])\n",
    "        # ampErr = np.sqrt(covar[0][0]) * amp\n",
    "\n",
    "\n",
    "        # predict_errs = ([1] + ydata) - powerLawFunc(amp, index, range(1, len(ydata) + 2))\n",
    "        # print(predict_errs)\n",
    "        # mu, std = norm.fit(predict_errs)\n",
    "        # plt.hist(predict_errs, density=True, alpha=0.6, color='g')\n",
    "        # plt_xmin, plt_xmax = plt.xlim()\n",
    "        # plt_x = np.linspace(plt_xmin, plt_xmax, 100)\n",
    "        # p = norm.pdf(plt_x, mu, std)\n",
    "        # plt.plot(plt_x, p, 'k', linewidth=2)\n",
    "        # title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "        # plt.title(title)\n",
    "        # plt.show()\n",
    "\n",
    "        sig = norm.cdf(1 - powerLawFunc(amp, index, 1), 0, 0.3)\n",
    "        # print(predict_err, sig)\n",
    "        #  [breakdown_value, sig]\n",
    "        return [keys[0], sig]\n",
    "\n",
    "    except TypeError:\n",
    "        return [keys[0], -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_top1_insight(subspace_df, breakdown, measure):\n",
    "    global sum_impact\n",
    "    breakdown_measure_dict = dict(zip(list(subspace_df[breakdown]),list(subspace_df[measure])))\n",
    "    res = point_power_law(breakdown_measure_dict)\n",
    "    # result_dict = dict(zip(\n",
    "    #     ['breakdown','breakdown_value', 'measure', 'predict', 'abs_impact', 'insight', 'insight_type', 'score'],\n",
    "    #     [breakdown] + res + [absolute_impact, 'top1', 'point', random.random()]))\n",
    "    result_dict = dict(zip(\n",
    "    ['breakdown','breakdown_value', 'sig'],\n",
    "    [breakdown] + res ))\n",
    "    return result_dict\n",
    "\n",
    "def get_subspace_df(subspace_condition_dict, df):\n",
    "    condition = pd.Series(True, index=df.index)\n",
    "    for feature in subspace_condition_dict:\n",
    "        if subspace_condition_dict[feature] == '*':\n",
    "            continue\n",
    "        condition = condition & (df[feature] == subspace_condition_dict[feature])\n",
    "    return df[condition]\n",
    "\n",
    "def calc_top1_insights(subspace_condition_dict, breakdown, measure, subspace_df, impact):\n",
    "    global sum_impact\n",
    "    if subspace_df.shape[0] == 0:\n",
    "        return None\n",
    "    grouped_df = subspace_df.groupby(breakdown, as_index=False).sum()\n",
    "    calc_dict = calc_top1_insight(grouped_df, breakdown, measure)\n",
    "    res_dict = dict(zip(['impact', 'insight', 'insight_type', 'score'],\n",
    "                        [impact, 'top1', 'point', calc_dict.get('sig')*impact]))\n",
    "    top1_insight = dict(subspace_condition_dict, **calc_dict, **res_dict)\n",
    "    return top1_insight\n",
    "\n",
    "def calc_trend_insights(subspace_condition_dict, breakdown, measure, subspace_df, impact):\n",
    "    global time_col\n",
    "    global sum_impact\n",
    "    if subspace_df.shape[0] == 0 or breakdown != time_col or subspace_condition_dict[time_col] != '*':\n",
    "        return None\n",
    "    grouped_df = subspace_df.groupby(breakdown, as_index=False).sum()\n",
    "    #  Calculate trend insight\n",
    "    x = grouped_df[breakdown].values #\n",
    "    y = grouped_df[measure].values #\n",
    "    x = x.reshape(-1, 1) #\n",
    "    y = y.reshape(-1, 1) #\n",
    "    if x.shape[0] < 2: return None\n",
    "    reg = LinearRegression().fit(x, y) #\n",
    "    slope = reg.coef_[0][0] #\n",
    "    r2_score = reg.score(x, y)\n",
    "    # sig = r2_score * norm.cdf(abs(slope), 0.2, 10000)\n",
    "    sig = r2_score\n",
    "    # grouped_df.plot(x=breakdown, y=measure)\n",
    "    # plt.plot(grouped_df[breakdown], reg.predict(x))\n",
    "    # plt.title(\"Sig Score is: {}, subspace condition: {}\".format(sig, subspace_condition_dict))\n",
    "    # plt.show()\n",
    "    # print(subspace_condition_dict, \"Sig: \", sig, \"Impact: \", impact)\n",
    "    result_dict = dict(zip(['breakdown','breakdown_value', 'sig', 'impact', 'insight', 'insight_type',\n",
    "                            'score'],\n",
    "                           [breakdown, -1] + [sig, impact] + ['trend', 'shape', sig*impact]))\n",
    "    trend_insight = dict(subspace_condition_dict, **result_dict)\n",
    "    return trend_insight\n",
    "\n",
    "def calc_change_point_abs(y, y_MA):\n",
    "    y_change = []\n",
    "    for index in range(len(y)):\n",
    "        if index == 0 or index == len(y) - 1:\n",
    "            y_change.append(0)\n",
    "        elif 1 <= index < len(y) - 2:\n",
    "            y_change.append(abs(y_MA[index-1] - y_MA[index+2]))\n",
    "        elif index == len(y) - 2:\n",
    "            y_change.append(abs(y_MA[index-1] - y[index+1]))\n",
    "    return y_change\n",
    "\n",
    "def calc_change_point_sigma(y, y_MA, y_MA_square):\n",
    "    y_sigma = []\n",
    "    for index in range(len(y)):\n",
    "        if index == 0 or index == len(y) - 1:\n",
    "            y_sigma.append(0)\n",
    "        elif 1 <= index < len(y) - 2:\n",
    "            res = np.sqrt((y_MA_square[index-1] + y_MA_square[index+2])/2 - np.square(y_MA[index-1] + y_MA[index+2]) / 4)\n",
    "            y_sigma.append(res)\n",
    "        elif index == len(y) - 2:\n",
    "            res = np.sqrt((y_MA_square[index-1] + y[index+1]**2)/2 - np.square(y_MA[index-1] + y[index+1]) / 4)\n",
    "            y_sigma.append(res)\n",
    "    return y_sigma\n",
    "\n",
    "def calc_change_point_insights(subspace_condition_dict, breakdown, measure, subspace_df, impact):\n",
    "    global sum_impact\n",
    "    MA_size = 2\n",
    "    if subspace_df.shape[0] == 0 or breakdown != time_col or subspace_condition_dict[time_col] != '*':\n",
    "        return None\n",
    "    grouped_df = subspace_df.groupby(breakdown, as_index=False).sum()\n",
    "    x = grouped_df[breakdown].values\n",
    "    y = grouped_df[measure].values\n",
    "    if len(y) < 4:\n",
    "        return None\n",
    "    y_MA = uniform_filter1d(y, size=MA_size, mode='nearest')\n",
    "    y_MA_square = uniform_filter1d(np.square(y), size=MA_size, mode='nearest')\n",
    "    y_change = calc_change_point_abs(y, y_MA)\n",
    "    y_sigma = calc_change_point_sigma(y=y, y_MA=y_MA, y_MA_square=y_MA_square)\n",
    "    k_mean = [y_change[i] / y_sigma[i] if y_sigma[i]!=0 else 0 for i in range(1, len(y) - 1)]\n",
    "    k_mean_max = max(k_mean)\n",
    "    sig = norm.cdf(k_mean_max * np.square(MA_size))\n",
    "    breakdown_value = x[k_mean.index(k_mean_max) + 1]\n",
    "    # print(\"The significance is {}, with value = {}\".format(sig, breakdown_value))\n",
    "    result_dict = dict(zip(['breakdown','breakdown_value', 'sig', 'impact', 'insight', 'insight_type',\n",
    "                            'score'],\n",
    "                           [breakdown, breakdown_value] + [sig, impact] + ['change point', 'shape', sig*impact]))\n",
    "    change_point_insight = dict(subspace_condition_dict, **result_dict)\n",
    "    if not sig:\n",
    "        return None\n",
    "    return change_point_insight\n",
    "\n",
    "def calc_outlier_insights(subspace_condition_dict, breakdown, measure, subspace_df, impact):\n",
    "    global sum_impact\n",
    "    if subspace_df.shape[0] == 0 or breakdown != time_col or subspace_condition_dict[time_col] != '*':\n",
    "        return None\n",
    "    grouped_df = subspace_df.groupby(breakdown, as_index=False).sum()\n",
    "    x = grouped_df[breakdown].values\n",
    "    y = grouped_df[measure].values\n",
    "    if len(y) < 4:\n",
    "        return None\n",
    "    mean = np.mean(y)\n",
    "    std = np.std(y)\n",
    "    z_score = (y - mean) / std\n",
    "    z_score_max_index = np.argmax(z_score)\n",
    "    z_score_max = z_score[z_score_max_index]\n",
    "    sig = norm.cdf(z_score_max)\n",
    "    breakdown_value = x[z_score_max_index]\n",
    "    if math.isnan(sig) :\n",
    "        return None\n",
    "    # print(\"The significance is {}, with value = {}, kmeans is {}\".format(sig, breakdown_value, z_score_max))\n",
    "    result_dict = dict(zip(['breakdown','breakdown_value', 'sig', 'impact', 'insight', 'insight_type',\n",
    "                            'score'],\n",
    "                           [breakdown, breakdown_value] + [sig, impact] + ['outlier', 'shape', sig*impact]))\n",
    "    outlier_insight = dict(subspace_condition_dict, **result_dict)\n",
    "\n",
    "    return outlier_insight\n",
    "\n",
    "def calc_attribution_insights(subspace_condition_dict, breakdown, measure, subspace_df, impact):\n",
    "    global sum_impact\n",
    "    if subspace_df.shape[0] == 0:\n",
    "        return None\n",
    "    grouped_df = subspace_df.groupby(breakdown, as_index=False).sum()\n",
    "    x = grouped_df[breakdown].values\n",
    "    y = grouped_df[measure].values\n",
    "    if np.sum(y) == 0:\n",
    "        return None\n",
    "    portion = np.max(y)/np.sum(y)\n",
    "\n",
    "    if portion < 0.5:\n",
    "        return None\n",
    "\n",
    "    sig = norm.cdf(portion, 0.5, 0.3)\n",
    "    breakdown_index = np.argmax(y)\n",
    "\n",
    "    result_dict = dict(zip(['breakdown','breakdown_value', 'sig', 'impact', 'insight', 'insight_type',\n",
    "                            'score'],\n",
    "                           [breakdown, x[breakdown_index]] + [sig, impact] + ['attribution', 'point', sig*impact]))\n",
    "    attribution_insight = dict(subspace_condition_dict, **result_dict)\n",
    "    return attribution_insight\n",
    "\n",
    "def calc_evenness_insights(subspace_condition_dict, breakdown, measure, subspace_df, impact):\n",
    "    global sum_impact\n",
    "    if subspace_df.shape[0] == 0 or breakdown != time_col or subspace_condition_dict[time_col] != '*':\n",
    "        return None\n",
    "    grouped_df = subspace_df.groupby(breakdown, as_index=False).sum()\n",
    "    x = grouped_df[breakdown].values\n",
    "    y = grouped_df[measure].values\n",
    "    if len(y) == 1: return None\n",
    "    std = np.std(y)\n",
    "    # print(std)\n",
    "    sig = 2 * (1 - norm.cdf(std, 0, 3))\n",
    "    result_dict = dict(zip(['breakdown','breakdown_value', 'sig', 'impact', 'insight', 'insight_type',\n",
    "                            'score'],\n",
    "                           [breakdown, -1] + [sig, impact] + ['evenness', 'point', sig*impact]))\n",
    "    evenness_insight = dict(subspace_condition_dict, **result_dict)\n",
    "    return evenness_insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_array(arr, index, val):\n",
    "    new_arr = arr[:]\n",
    "    new_arr[index] = val\n",
    "    return new_arr\n",
    "\n",
    "def generate_process_node(feature_names, measure, output_array, df,\n",
    "                          calc_insights = lambda: \"Need to define\", breakdowns = [], top_num = 50):\n",
    "    def process_node(node):\n",
    "        star_feature_name = [feature_names[index] for index in range(len(node)) if node[index] == '*']\n",
    "        current_breakdowns = star_feature_name if len(breakdowns) == 0 else breakdowns\n",
    "        for breakdown in current_breakdowns:\n",
    "            # subspace_condition_dict. e.g., ['Year', 'Brand', 'Category'] ['2007', '*', '*']\n",
    "            subspace_df = get_subspace_df(dict(zip(feature_names, node)), df)\n",
    "            impact = subspace_df[measure].count() / sum_impact\n",
    "            subspace_condition_dict = dict(zip(feature_names, node))\n",
    "\n",
    "            if len(output_array) == top_num and output_array[0][0] > impact:\n",
    "                return False\n",
    "\n",
    "            insight = calc_insights(subspace_condition_dict=subspace_condition_dict,\n",
    "                         breakdown=breakdown, measure=measure, impact = impact, subspace_df=subspace_df)\n",
    "            if insight:\n",
    "                # output.append(insight)\n",
    "                if len(output_array) < top_num:\n",
    "                    heapq.heappush(output_array, (insight.get('score'), random.random(), insight))\n",
    "                elif output_array[0][0] < insight.get('score'):\n",
    "                    heapq.heapreplace(output_array, (insight.get('score'), random.random(), insight))\n",
    "        if node.count('*') == 1:\n",
    "            return False\n",
    "        return True\n",
    "    return process_node\n",
    "\n",
    "def BFS_tranverse_and_process(df, feature_names, process_node = lambda x: True):\n",
    "    feature_unique_value_matrix = [df[feature].unique().tolist() for feature in feature_names]\n",
    "    traverse_root = ['*' for i in feature_names] + [[]]\n",
    "    result_stack = [traverse_root] \n",
    "    \n",
    "    while len(result_stack) > 0:\n",
    "        *root, ban = result_stack.pop(0)\n",
    "        result = process_node(root)\n",
    "        if not result:\n",
    "            continue\n",
    "        banned_index = ban[:]\n",
    "        for col_index, val_index in enumerate(root):\n",
    "            if col_index in banned_index:\n",
    "                continue\n",
    "            banned_index.append(col_index)\n",
    "            banned_index = list(set(banned_index))\n",
    "            if val_index == '*':\n",
    "                result_stack += ([generate_array(root, col_index, val)+[banned_index[:]]  for val in feature_unique_value_matrix[col_index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Keys:  ['Year', 'Brand', 'Category']\n",
      "{'Year': 5, 'Brand': 8, 'Category': 8}\n",
      "Time Elapsed: 1.3813107013702393\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "output1= []\n",
    "output2= []\n",
    "output3= []\n",
    "output4= []\n",
    "output5= []\n",
    "\n",
    "# CarSales1.csv\n",
    "feature_names = ['Year', 'Brand', 'Category']\n",
    "measure = 'Sales'\n",
    "time_col = 'Year'\n",
    "data[time_col] = data[time_col].apply(lambda year_string: year_string.split('/')[0])\n",
    "\n",
    "\n",
    "# carSales2.csv\n",
    "# feature_names = ['Year', 'Brand', 'Body', 'Engine Type', 'EngineV', 'Model', 'Registration']\n",
    "# measure = 'Price'\n",
    "# time_col = 'Year'\n",
    "\n",
    "\n",
    "# Census.csv\n",
    "# feature_names = ['Birthday', 'Age Segment', 'Marital Status', 'Sex', 'Age Group']\n",
    "# measure = 'Count of persons'\n",
    "# time_col = 'Birthday'\n",
    "#\n",
    "# data[time_col] = data[time_col].apply(lambda year_string: year_string.split('/')[0])\n",
    "\n",
    "\n",
    "# Emission.csv\n",
    "# feature_names = ['Year', 'State', 'Producer Type', 'Energy Source']\n",
    "# measure = 'CO2 (kt)'\n",
    "# time_col = 'Year'\n",
    "\n",
    "\n",
    "sum_impact = data[measure].count()\n",
    "feature_names = subspace_ordering(feature_measures=feature_names, df=data)\n",
    "\n",
    "process_node_trend = generate_process_node(feature_names = feature_names,\n",
    "                                     output_array=output1,\n",
    "                                     df = data,\n",
    "                                     measure = measure,\n",
    "                                     calc_insights=calc_trend_insights)\n",
    "\n",
    "BFS_tranverse_and_process(data,feature_names, process_node=process_node_trend)\n",
    "\n",
    "process_node_top1 = generate_process_node(feature_names = feature_names,\n",
    "                                     output_array=output2,\n",
    "                                     df = data,\n",
    "                                     measure = measure,\n",
    "                                     calc_insights=calc_top1_insights)\n",
    "\n",
    "BFS_tranverse_and_process(data,feature_names, process_node=process_node_top1)\n",
    "\n",
    "process_node_change_point = generate_process_node(feature_names = feature_names,\n",
    "                                     output_array=output3,\n",
    "                                     df = data,\n",
    "                                     measure = measure,\n",
    "                                     calc_insights=calc_change_point_insights)\n",
    "\n",
    "BFS_tranverse_and_process(data,feature_names, process_node=process_node_change_point)\n",
    "\n",
    "\n",
    "process_node_outlier = generate_process_node(feature_names = feature_names,\n",
    "                                     output_array=output4,\n",
    "                                     df = data,\n",
    "                                     measure = measure,\n",
    "                                     calc_insights=calc_outlier_insights)\n",
    "\n",
    "BFS_tranverse_and_process(data,feature_names, process_node=process_node_outlier)\n",
    "#\n",
    "process_node_attribution = generate_process_node(feature_names = feature_names,\n",
    "                                     output_array=output5,\n",
    "                                     df = data,\n",
    "                                     measure = measure,\n",
    "                                     calc_insights=calc_attribution_insights)\n",
    "\n",
    "BFS_tranverse_and_process(data,feature_names, process_node=process_node_attribution)\n",
    "\n",
    "# process_node_evenness = generate_process_node(feature_names = feature_names,\n",
    "#                                      output_array=output,\n",
    "#                                      df = data,\n",
    "#                                      measure = measure,\n",
    "#                                      calc_insights=calc_evenness_insights)\n",
    "#\n",
    "# BFS_tranverse_and_process(data,feature_names, process_node=process_node_evenness)\n",
    "\n",
    "res = [out[-1] for out in output1]\\\n",
    "      + [out[-1] for out in output2]\\\n",
    "      + [out[-1] for out in output3]\\\n",
    "      + [out[-1] for out in output4]\\\n",
    "      + [out[-1] for out in output5]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df['measure'] = measure\n",
    "end_time = time.time()\n",
    "print(\"Time Elapsed: {}\".format(end_time-start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     Year  Brand    Category breakdown breakdown_value       sig    impact  \\\n0       *  Mazda         SUV      Year              -1  0.038017  0.018182   \n1       *    BMW         SUV      Year              -1  0.015964  0.054545   \n2       *      *         SUV      Year              -1  0.002184  0.400000   \n3       *    GMC           *      Year              -1  0.047839  0.109091   \n4       *  Mazda         MPV      Year              -1  0.049890  0.018182   \n..    ...    ...         ...       ...             ...       ...       ...   \n232  2011    GMC           *  Category             SUV  0.608955  0.021818   \n233     *      *         MPV     Brand           Mazda  0.952210  0.018182   \n234  2011      *      Sporty     Brand            Ford  0.860858  0.014545   \n235     *  Mazda           *  Category         Compact  0.534577  0.090909   \n236     *  Mazda  Subcompact      Year            2011  0.621458  0.018182   \n\n         insight insight_type     score measure  \n0          trend        shape  0.000691   Sales  \n1          trend        shape  0.000871   Sales  \n2          trend        shape  0.000873   Sales  \n3          trend        shape  0.005219   Sales  \n4          trend        shape  0.000907   Sales  \n..           ...          ...       ...     ...  \n232  attribution        point  0.013286   Sales  \n233  attribution        point  0.017313   Sales  \n234  attribution        point  0.012522   Sales  \n235  attribution        point  0.048598   Sales  \n236  attribution        point  0.011299   Sales  \n\n[237 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Brand</th>\n      <th>Category</th>\n      <th>breakdown</th>\n      <th>breakdown_value</th>\n      <th>sig</th>\n      <th>impact</th>\n      <th>insight</th>\n      <th>insight_type</th>\n      <th>score</th>\n      <th>measure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>*</td>\n      <td>Mazda</td>\n      <td>SUV</td>\n      <td>Year</td>\n      <td>-1</td>\n      <td>0.038017</td>\n      <td>0.018182</td>\n      <td>trend</td>\n      <td>shape</td>\n      <td>0.000691</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>*</td>\n      <td>BMW</td>\n      <td>SUV</td>\n      <td>Year</td>\n      <td>-1</td>\n      <td>0.015964</td>\n      <td>0.054545</td>\n      <td>trend</td>\n      <td>shape</td>\n      <td>0.000871</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>*</td>\n      <td>*</td>\n      <td>SUV</td>\n      <td>Year</td>\n      <td>-1</td>\n      <td>0.002184</td>\n      <td>0.400000</td>\n      <td>trend</td>\n      <td>shape</td>\n      <td>0.000873</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>*</td>\n      <td>GMC</td>\n      <td>*</td>\n      <td>Year</td>\n      <td>-1</td>\n      <td>0.047839</td>\n      <td>0.109091</td>\n      <td>trend</td>\n      <td>shape</td>\n      <td>0.005219</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>*</td>\n      <td>Mazda</td>\n      <td>MPV</td>\n      <td>Year</td>\n      <td>-1</td>\n      <td>0.049890</td>\n      <td>0.018182</td>\n      <td>trend</td>\n      <td>shape</td>\n      <td>0.000907</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>2011</td>\n      <td>GMC</td>\n      <td>*</td>\n      <td>Category</td>\n      <td>SUV</td>\n      <td>0.608955</td>\n      <td>0.021818</td>\n      <td>attribution</td>\n      <td>point</td>\n      <td>0.013286</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>233</th>\n      <td>*</td>\n      <td>*</td>\n      <td>MPV</td>\n      <td>Brand</td>\n      <td>Mazda</td>\n      <td>0.952210</td>\n      <td>0.018182</td>\n      <td>attribution</td>\n      <td>point</td>\n      <td>0.017313</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>234</th>\n      <td>2011</td>\n      <td>*</td>\n      <td>Sporty</td>\n      <td>Brand</td>\n      <td>Ford</td>\n      <td>0.860858</td>\n      <td>0.014545</td>\n      <td>attribution</td>\n      <td>point</td>\n      <td>0.012522</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>*</td>\n      <td>Mazda</td>\n      <td>*</td>\n      <td>Category</td>\n      <td>Compact</td>\n      <td>0.534577</td>\n      <td>0.090909</td>\n      <td>attribution</td>\n      <td>point</td>\n      <td>0.048598</td>\n      <td>Sales</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>*</td>\n      <td>Mazda</td>\n      <td>Subcompact</td>\n      <td>Year</td>\n      <td>2011</td>\n      <td>0.621458</td>\n      <td>0.018182</td>\n      <td>attribution</td>\n      <td>point</td>\n      <td>0.011299</td>\n      <td>Sales</td>\n    </tr>\n  </tbody>\n</table>\n<p>237 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 1.3813107013702393\n"
     ]
    }
   ],
   "source": [
    "print(\"Time Elapsed: {}\".format(end_time-start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nprint point insight result\\n'"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print point insight result\n",
    "\"\"\"\n",
    "# for insight in res:\n",
    "#     # breakdown_cond = {insight['breakdown']: insight['breakdown_value']}\n",
    "#     subspace_cond = {k:insight[k] for k in insight.keys() if k in feature_names}\n",
    "#     condition = dict(subspace_cond)\n",
    "#     selected_df = get_subspace_df(condition, data)\n",
    "#     grouped_df = selected_df.groupby(insight['breakdown'], as_index=False).sum()\n",
    "#     if insight['insight'] == 'top1':\n",
    "#         grouped_df = grouped_df.sort_values(by=[measure])\n",
    "#         grouped_df.plot(x=insight['breakdown'], y=measure, kind='bar')\n",
    "#     elif insight['insight'] == 'trend' or insight['insight'] == 'evenness':\n",
    "#         # print(grouped_df)\n",
    "#         grouped_df = grouped_df.sort_values(by=time_col)\n",
    "#         grouped_df.plot(x=insight['breakdown'], y=measure, kind='line')\n",
    "#     elif insight['insight'] == 'change point' or insight['insight'] == 'outlier':\n",
    "#         grouped_df = grouped_df.sort_values(by=time_col)\n",
    "#         y_val = grouped_df.loc[grouped_df[insight['breakdown']] == insight['breakdown_value']][measure]\n",
    "#         # print(insight['breakdown_value'], y_val.values[0])\n",
    "#         plt.plot(grouped_df[insight['breakdown']], grouped_df[measure])\n",
    "#         plt.plot([insight['breakdown_value']], [y_val.values[0]],color='red', marker='o', markersize=3)\n",
    "#     elif insight['insight'] == 'attribution':\n",
    "#         grouped_df = grouped_df.sort_values(by=[measure])\n",
    "#         plt.pie(grouped_df[measure], labels = grouped_df[insight['breakdown']], startangle = 90,\n",
    "#         counterclock = False)\n",
    "#         plt.axis('square')\n",
    "#\n",
    "#     plt.title(condition)\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "with open('C:\\\\Users\\\\52497\\\\Dropbox\\\\VIS\\\\Insight\\\\res\\\\insights_carSales1.csv', 'w+') as file:\n",
    "    df.to_csv(file, index=False, line_terminator='\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py38",
   "language": "python",
   "display_name": "Python 3.8 (py38)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}